# Example Keisei DRL Shogi configuration (YAML)
env:
  seed: 42
  device: "cpu"
  input_channels: 46
  max_moves_per_game: 500
training:
  learning_rate: 0.0003
  gamma: 0.99
  clip_epsilon: 0.2
  ppo_epochs: 4
  minibatch_size: 64
  value_loss_coeff: 0.5
  entropy_coef: 0.01
  steps_per_epoch: 2048
  total_timesteps: 500000
  checkpoint_interval_timesteps: 2000
evaluation:
  enable_periodic_evaluation: true
  evaluation_interval_timesteps: 10000
  num_games: 20
  opponent_type: "random"
  max_moves_per_game: 500
  log_file_path_eval: "eval_log.txt"
  wandb_log_eval: false
logging:
  model_dir: "models"
  log_file: "training_log.txt"
wandb:
  enabled: true
  entity: null
  log_model_artifact: false

parallel:
  enabled: false                  # Enable parallel experience collection
  num_workers: 4                  # Number of parallel workers for experience collection
  batch_size: 32                  # Batch size for experience transmission from workers
  sync_interval: 100              # Steps between model weight synchronization
  compression_enabled: true       # Enable compression for model weight transmission
  timeout_seconds: 10.0           # Timeout for worker communication operations
  max_queue_size: 1000            # Maximum size of experience queues
  worker_seed_offset: 1000        # Offset for worker random seeds to ensure diversity

demo:
  enable_demo_mode: false  # If true, enables demo mode with per-move delay and extra logging
  demo_mode_delay: 0.01     # Delay in seconds between moves in demo mode
