### **Executable Plan: Critical Fixes & Technical Debt Reduction**

#### **Task 2.1: Resolve Non-Functional Configuration Override**

**Objective:** Implement or remove the `--override` command-line flag, which is currently a non-functional stub that can mislead users[cite: 16, 38, 178]. The following steps will implement the feature in a robust way.

**Steps:**

1.  **Locate the Target Function:**
    * Navigate to the `apply_config_overrides` function in `keisei/train.py`. If the Step 1 refactor is complete, this logic might be in a configuration setup utility or within the `Trainer` class.

2.  **Implement Override Parsing Logic:**
    * Modify the function to iterate through the list of override strings provided by `argparse`.
    * For each string (e.g., `"LEARNING_RATE=0.001"`), parse it:
        * Check for the presence of an `=` character. If not present, log a warning and skip.
        * Split the string into a `key` and `value` pair.
        * Use `ast.literal_eval` on the `value` string to safely convert it to a Python literal (e.g., float, int, bool). Wrap this in a `try...except` block to handle potential `ValueError` or `SyntaxError` for malformed values.

3.  **Implement Nested Attribute Assignment:**
    * The configuration uses nested `SimpleNamespace` objects (e.g., `cfg.EVALUATION_CONFIG.NUM_GAMES`)[cite: 121, 187]. The key must be parsed to handle this.
    * Split the `key` by `.` (dots).
    * Iterate through the parts of the key to traverse the nested `cfg` object, arriving at the final attribute to be set. For the last part of the key, use `setattr()` to assign the parsed `value`.

4.  **Add User Feedback:**
    * As recommended by the audit[cite: 239], after successfully applying an override, add a log message confirming the change (e.g., `INFO: Config override applied: LEARNING_RATE = 0.001`).
    * Remove the existing `"is a stub and does not actually apply overrides"` warning[cite: 16].

**Verification:**

1.  **Unit Test:** Create a new test in `tests/test_train.py` (or a relevant test file) that calls the `apply_config_overrides` function directly. Assert that it correctly modifies a sample `cfg` object for both top-level and nested attributes.
2.  **End-to-End Test:** Run the training script with a functional override and confirm the behavior changes. For example: `python keisei/train.py --override TOTAL_TIMESTEPS=10`. The training should stop after exactly 10 timesteps, as suggested in the audit's testing plan[cite: 246].

---

#### **Task 2.2: Correct Configuration Inconsistencies**

**Objective:** Resolve the discrepancy in the `NUM_ACTIONS_TOTAL` constant to prevent potential bugs and confusion[cite: 39, 41].

**Steps:**

1.  **Correct the Constant in `config.py`:**
    * Open the `config.py` file.
    * Locate the line: `NUM_ACTIONS_TOTAL = 31592`[cite: 24, 39].
    * Change the value to `13527`, which is the correct number of unique moves generated by `PolicyOutputMapper`[cite: 25, 26].
    * Add a comment to clarify the source of this value: `# Total number of unique moves (board moves + drops) generated by PolicyOutputMapper`.

2.  **Remove Hardcoded Values:**
    * Search the entire codebase for any hardcoded instances of `13527`.
    * The audit specifically notes that `evaluate.py` hardcodes this value[cite: 40].
    * Replace any findings with a reference to the central configuration value (e.g., `cfg.NUM_ACTIONS_TOTAL`) to ensure a single source of truth.

**Verification:**

1.  **Run Existing Tests:** The test suite for `PolicyOutputMapper` in `tests/test_utils.py` already verifies that the total move count is exactly 13,527[cite: 129, 362]. Re-running the test suite will confirm that the change has not introduced any regressions.
2.  **Code Search:** Use a tool like `grep` or your IDE's search function to confirm that the incorrect value `31592` no longer exists in the codebase.

---

#### **Task 2.3: Implement Deterministic Environment Seeding**

**Objective:** Implement seeding in the `ShogiGame` environment to ensure full experimental reproducibility, addressing a gap noted in the audit[cite: 66, 240].

**Steps:**

1.  **Add `seed()` Method to Game Engine:**
    * Open `keisei/shogi/shogi_game.py`.
    * Add a new method to the `ShogiGame` class: `def seed(self, seed_value=None):`.
    * *Note: Standard Shogi is deterministic. This method serves as an interface for potential future randomization (e.g., stochastic variants) and to fulfill the contract of a fully reproducible environment. If the game has no internal random number generator, this method can simply be `pass` for now.*

2.  **Call `seed()` Method During Training Setup:**
    * Open `keisei/train.py` (or `keisei/trainer.py` post-refactor).
    * Locate the line where the `ShogiGame` is instantiated (e.g., `game = ShogiGame()`).
    * Immediately after instantiation, add the following code, which acts on the hint found in the code comments[cite: 68]:
        ```python
        if cfg.SEED is not None:
            game.seed(cfg.SEED)
        ```

**Verification:**

1.  **Manual Reproducibility Check:**
    * Run a short training session with a fixed seed: `python keisei/train.py --seed 123`.
    * Save the log file that contains the sequence of moves.
    * Run the exact same command again.
    * Compare the log files from both runs. The sequence of game states and moves for at least the first episode should be identical.

---

#### **Task 2.4: Prune Unused Dependencies**

**Objective:** Clean up the `requirements.txt` file by removing packages that are included but not used, reducing bloat and potential security vulnerabilities[cite: 99, 241].

**Steps:**

1.  **Edit `requirements.txt`:**
    * Open the `requirements.txt` file.
    * Based on the audit's findings, delete the lines for the following packages:
        * `networkx` [cite: 413]
        * `sympy` [cite: 413]
        * `GitPython` [cite: 415]
        * `tqdm` (as it was replaced by `rich`) [cite: 417]
    * The audit also questions the use of `sentry-sdk`, which is included but not implemented[cite: 418]. A decision should be made: either remove it or implement it in a subsequent task. For this task, assume it will be removed.

2.  **Recreate and Test the Environment:**
    * To ensure no dependency was removed by mistake, create a new, clean Python virtual environment.
    * Activate the new environment.
    * Install the dependencies from the newly pruned `requirements.txt` file: `pip install -r requirements.txt`.
    * Run the entire project test suite within this clean environment.

**Verification:**

* The successful completion of the entire test suite (`pytest`) in the clean environment confirms that the removed packages were not required for the project's core functionality or tests. An `ImportError` during the test run would indicate a dependency was incorrectly removed.