Below is a refreshed **Shogi DRL / Keisei Code Map – rev 29 May 2025**.
Additions/changes since the earlier draft are **highlighted in *italics***.

*(Words of Estimative Probability appear in the “Accuracy” column.)*

---

| #      | Sub-system                      | Sections & Purpose                                                                                                                                                                          | Core / Supporting Files                                                                                                     | Reviewer Watch-list (issues & risks)                                                                                                                                                                                                                                                                                                                                                                 | Accuracy       |
| :----- | :------------------------------ | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | :-------------------------------------------------------------------------------------------------------------------------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------- |
| **1**  | **Configuration & Overrides**   | Pydantic schema; YAML/JSON/CLI/env loaders.<br/>Consumers: `training` & `evaluation` CLIs, `Trainer`, `SessionManager`, `ModelManager`, `EnvManager`.                                       | `config_schema.py`; `utils/utils.py` (`load_config`, `FLAT_KEY_TO_NESTED`); `training/train*.py`; `evaluation/evaluate.py`. | • `num_actions_total` vs `PolicyOutputMapper` validated by `EnvManager`.<br/>• *Device-string validator still missing (typo e.g. `cuda:O` silently passes).*<br/>• Complex override precedence in `load_config` – document plainly.<br/>• Keep `default_config.yaml` ↔ `config_schema.py` aligned.<br/>• Redundant CLI parsing between the two train scripts.                                        | Almost Certain |
| **2**  | **Shogi Engine Core**           | `shogi_core_definitions.py`, `shogi_game.py`, rule logic, move exec, I/O & features (duplication noted).                                                                                    | All `shogi/*` modules shown.                                                                                                | • `copy.deepcopy` & list scans may bottleneck.<br/>• Replace `DEBUG_*` prints with `logging`.<br/>• Stress-test `uchi-fu-zume`, `sennichite`, mandatory promotion.<br/>• Unit-test SFEN & KIF conversions.<br/>• Observation builder duplicated in `features.py` vs `shogi_game_io.py` – refactor. <br/>• *`board_history` now used for repetition; ensure memory won’t balloon in very long games.* | Highly Likely  |
| **3**  | **Policy ↔ Move Mapping**       | Action-index ⇆ `MoveTuple` ⇆ USI.                                                                                                                                                           | `utils.utils.PolicyOutputMapper`.                                                                                           | • 13 527-action space must equal `EnvConfig.num_actions_total` (checked).<br/>• Heuristic fallback for `PieceType` identity still brittle.<br/>• Consider explicit mapping versioning in checkpoints.<br/>• Robustly test `−∞` logits → NaN path.                                                                                                                                                    | Almost Certain |
| **4**  | **Neural-Net Models**           | Simple `core.ActorCritic` vs ResNet-tower `training.models.*`; factory picks model.                                                                                                         | `core/neural_network.py`; `training/models/*`.                                                                              | • **CRITICAL**: Model mismatch between `PPOAgent` default and Trainer’s ResNet injection – ensure shared API.<br/>• `checkpoint.load_checkpoint_with_padding` patches only `stem.weight`; generalise.<br/>• BatchNorm stats portability.<br/>• Warn if “dummy” model selected in production.                                                                                                         | Highly Likely  |
| **5**  | **Reinforcement-Learning Core** | PPO agent, experience buffer.                                                                                                                                                               | `core/ppo_agent.py`; `core/experience_buffer.py`.                                                                           | • List-based buffer & per-step legal-mask tensor (13 k bools) may exhaust RAM – investigate compressed/sparse or regenerate on-the-fly.<br/>• `ExperienceBuffer.get_batch()` returns empty dict on shape errors – silent training skip risk.<br/>• Hyper-parameter sanity (clip ε, GA E λ, grad-clip).                                                                                               | Highly Likely  |
| **6**  | **Environment & Managers**      | *NEW:* `EnvManager` bootstraps `ShogiGame`, validates action-space, applies seeding; *SessionManager* creates dirs, run-names, W\&B; *StepManager* owns per-step orchestration & demo-mode. | `training/env_manager.py`; `training/session_manager.py`; `training/step_manager.py`.                                       | • Action-space mismatch raises early fatal error – good guard-rail.<br/>• `StepManager` demo-mode sleeps each ply – fine for demos, disable for perf runs.<br/>• *SessionManager names runs via `generate_run_name`; collisions possible on high-rate CI.*                                                                                                                                           | Likely         |
| **7**  | **Training Orchestration & UI** | Trainer loop, callbacks, Rich TUI.                                                                                                                                                          | `training/trainer.py`; `training/display.py`; `training/callbacks.py`.                                                      | • **CRITICAL** resume gap: `ModelManager.handle_checkpoint_resume()` loads counters into `PPOAgent`, *but Trainer never copies them*, so stats & schedules reset. Root cause lives here.<br/>• Periodic evaluation callback blocks main loop – consider thread/process.<br/>• High-frequency flush on NFS may throttle (`TrainingLogger`).                                                           | Highly Likely  |
| **8**  | **Evaluation Pipeline**         | Evaluator wrapper, core loop, CLI.                                                                                                                                                          | `evaluation/evaluate.py`; `evaluation/loop.py`; `utils/agent_loading.py`.                                                   | • Loop still feeds **all-ones** legal mask – agent can attempt illegal moves and be “skipped”; replace with proper mask.<br/>• W\&B init guarded but noisy; unify style with training path.                                                                                                                                                                                                          | Highly Likely  |
| **9**  | **Logging / Checkpoint / W\&B** | Plain + Rich loggers, checkpoint save/load & migration, W\&B artefacts.                                                                                                                     | `utils/utils.TrainingLogger`; `utils/checkpoint.py`; `training/model_manager.py`.                                           | • Still mixing `print` & `logging`.<br/>• Only first conv layer padding supported.<br/>• Buffered writes recommended for network filesystems.                                                                                                                                                                                                                                                        | Almost Certain |
| **10** | **Entry-points & Packaging**    | CLIs, `__init__.py` re-exports, package surface.                                                                                                                                            | root & subpackage `__init__.py`; `train.py`, `train_wandb_sweep.py`, `evaluate.py`.                                         | • Static cycle check still advisable.<br/>• Ensure top-level re-exports don’t trigger heavy imports.                                                                                                                                                                                                                                                                                                 | Likely         |

---

### New/expanded focus areas

* **ExperienceBuffer silent-failure path** – when stacking tensors fails, training simply receives an empty metrics dict and soldiers on.  Add explicit assert or raise.
* **Trainer ↔ ModelManager resume handshake** – propagate `global_timestep`, `episodes`, win/draw stats after `agent.load_model()` or Trainer will double-count.
* **EnvManager** could adopt device-string validation to centralise the check flagged in row 1.
* **Repetition (`board_history`) GC** – if you ever raise `max_moves_per_game`, memory will creep up; consider ring-buffer.

Feel free to slice this table into separate Markdown pages (one per row) if you need finer navigation, or shout if you want JSON/YAML exports instead.
